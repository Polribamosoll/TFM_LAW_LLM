{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.41.1)\n",
      "Requirement already satisfied: langchain_pinecone in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.32)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.40 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_pinecone) (0.1.42)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (1.26.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.1.45)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\polri\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers langchain_pinecone datasets pinecone-client langchain-community scikit-learn langchain datasets transformers==4.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.17\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/67.9 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/67.9 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 30.7/67.9 kB 262.6 kB/s eta 0:00:01\n",
      "     ---------------------------------- --- 61.4/67.9 kB 469.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 67.9/67.9 kB 369.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (2.31.0)\n",
      "Collecting sacremoses (from transformers==4.17)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.17) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\polri\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers==4.17) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers==4.17) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers==4.17) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers==4.17) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers==4.17) (2024.2.2)\n",
      "Requirement already satisfied: click in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sacremoses->transformers==4.17) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sacremoses->transformers==4.17) (1.4.0)\n",
      "Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 24.5 MB/s eta 0:00:00\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 897.5/897.5 kB 28.6 MB/s eta 0:00:00\n",
      "Installing collected packages: sacremoses, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.1\n",
      "    Uninstalling transformers-4.41.1:\n",
      "      Successfully uninstalled transformers-4.41.1\n",
      "Successfully installed sacremoses-0.1.1 transformers-4.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "optimum 1.19.2 requires transformers[sentencepiece]<4.41.0,>=4.26.0, but you have transformers 4.17.0 which is incompatible.\n",
      "sentence-transformers 2.6.1 requires transformers<5.0.0,>=4.32.0, but you have transformers 4.17.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\polri\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.29.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\polri\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\polri\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\polri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/302.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 20.5/302.6 kB 165.2 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 41.0/302.6 kB 281.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/302.6 kB 774.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.6/302.6 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.29.2\n",
      "    Uninstalling accelerate-0.29.2:\n",
      "      Successfully uninstalled accelerate-0.29.2\n",
      "Successfully installed accelerate-0.30.1\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys \n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "# Load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need the following torch configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch config\n",
    "from torch import cuda, bfloat16, float16\n",
    "import torch\n",
    "\n",
    "# Torch options\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters from YAML file\n",
    "import os\n",
    "\n",
    "# Change the current working directory to the directory containing the YAML file\n",
    "os.chdir('/notebooks/TFM_LAW_LLM')\n",
    "\n",
    "# Load parameters from YAML file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use optimum\n",
    "use_optimum = config[\"use_optimum\"]\n",
    "\n",
    "# Show\n",
    "use_optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\polri\\\\Desktop\\\\Git_TFM\\\\TFM_LAW_LLM'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set directory to file location\n",
    "from pathlib import Path\n",
    "notebook_location = Path(os.path.abspath(''))\n",
    "os.chdir(notebook_location)\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "current_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utility libraries\n",
    "import os \n",
    "\n",
    "# PyTorch library for deep learning\n",
    "import torch  \n",
    "\n",
    "# HuggingFace Transformers library for natural language processing\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer \n",
    "\n",
    "# Dataset handling library from HuggingFace\n",
    "from datasets import Dataset  \n",
    "\n",
    "# Pinecone related\n",
    "import pinecone  \n",
    "from pinecone import Pinecone  \n",
    "\n",
    "# LangChain integration with Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore  \n",
    "\n",
    "# Transformers pipeline \n",
    "from transformers import pipeline  \n",
    "\n",
    "# LangChain library for creating embeddings with HuggingFace\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings  \n",
    "\n",
    "# Scikit-learn library for machine learning\n",
    "from sklearn.model_selection import train_test_split  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1068}},\n",
       " 'total_vector_count': 1068}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Pinecone\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "index_name = config[\"index_name\"]\n",
    "pinecone = Pinecone(api_key = \"api_key\")\n",
    "\n",
    "# Connect\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "401 Client Error. (Request ID: Root=1-665df042-64c49e2e19465a9c026af3a0)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/dariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn/resolve/main/model.safetensors.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "User Access Token \"nacho\" is expired\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "dariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn is not a local folder or a valid repository name on 'https://hf.co'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/dariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn/resolve/main/model.safetensors",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:631\u001b[0m, in \u001b[0;36mhas_file\u001b[1;34m(path_or_repo, filename, revision, proxies, token, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-665df042-64c49e2e19465a9c026af3a0)\n\nRepository Not Found for url: https://huggingface.co/dariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn/resolve/main/model.safetensors.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nUser Access Token \"nacho\" is expired",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the embedding model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m embed_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define query and retrieve documents\u001b[39;00m\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m¿Qué diferencia hay entre homicidio y asesinato según el Código Penal español, y cuáles son las penas asociadas a cada uno?\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:72\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43msentence_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:191\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[0;32m    188\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(model_name_or_path, token, cache_folder\u001b[38;5;241m=\u001b[39mcache_folder, revision\u001b[38;5;241m=\u001b[39mrevision):\n\u001b[1;32m--> 191\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    200\u001b[0m         model_name_or_path,\n\u001b[0;32m    201\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    205\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1233\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_args\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hub_kwargs\n\u001b[1;32m-> 1233\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;66;03m# Normalize does not require any files to be loaded\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_class \u001b[38;5;241m==\u001b[39m Normalize:\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:36\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     35\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     39\u001b[0m     tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path,\n\u001b[0;32m     40\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:65\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:3415\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3398\u001b[0m         has_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3399\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: revision,\n\u001b[0;32m   3400\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxies\u001b[39m\u001b[38;5;124m\"\u001b[39m: proxies,\n\u001b[0;32m   3401\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: token,\n\u001b[0;32m   3402\u001b[0m         }\n\u001b[0;32m   3403\u001b[0m         cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[0;32m   3405\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3413\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhas_file_kwargs,\n\u001b[0;32m   3414\u001b[0m         }\n\u001b[1;32m-> 3415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_weights_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhas_file_kwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   3416\u001b[0m             Thread(\n\u001b[0;32m   3417\u001b[0m                 target\u001b[38;5;241m=\u001b[39mauto_conversion,\n\u001b[0;32m   3418\u001b[0m                 args\u001b[38;5;241m=\u001b[39m(pretrained_model_name_or_path,),\n\u001b[0;32m   3419\u001b[0m                 kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_errors_during_conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs},\n\u001b[0;32m   3420\u001b[0m                 name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThread-autoconversion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3421\u001b[0m             )\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   3422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3423\u001b[0m     \u001b[38;5;66;03m# Otherwise, no PyTorch file was found, maybe there is a TF or Flax model file.\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m     \u001b[38;5;66;03m# We try those to give a helpful error message.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\polri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:642\u001b[0m, in \u001b[0;36mhas_file\u001b[1;34m(path_or_repo, filename, revision, proxies, token, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(e)\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder or a valid repository name on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://hf.co\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    644\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(e)\n",
      "\u001b[1;31mOSError\u001b[0m: dariolopez/roberta-base-bne-finetuned-msmarco-qa-es-mnrl-mn is not a local folder or a valid repository name on 'https://hf.co'."
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "embed_model_id = config[\"embed_model_id\"]\n",
    "embed_model = HuggingFaceEmbeddings(model_name=embed_model_id, model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",  # Truncate the context, not the question\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\").tolist()\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        start_char = examples[\"answers\"][i][\"answer_start\"]\n",
    "        end_char = start_char + len(examples[\"answers\"][i][\"text\"])\n",
    "\n",
    "        # Find the start and end token indices that correspond to the start and end character positions\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "\n",
    "        for j, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token_idx = j\n",
    "            if start < end_char <= end:\n",
    "                end_token_idx = j\n",
    "            if start_token_idx is not None and end_token_idx is not None:\n",
    "                break\n",
    "\n",
    "        if start_token_idx is None or end_token_idx is None:\n",
    "            start_token_idx = 0\n",
    "            end_token_idx = 0\n",
    "\n",
    "        start_positions.append(start_token_idx)\n",
    "        end_positions.append(end_token_idx)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a synthetic dataset with, questions, answers and contexts to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"question\": [\n",
    "        \"¿Cuál es la ley que regula el derecho al honor y la intimidad?\",\n",
    "        \"¿Qué artículo de la Constitución Española establece la igualdad ante la ley?\",\n",
    "        \"¿Qué establece el artículo 15 de la Constitución Española?\",\n",
    "        \"¿Qué es el habeas corpus según la ley española?\",\n",
    "        \"¿Qué regula la Ley Orgánica 3/2007?\",\n",
    "        \"¿Qué establece el artículo 47 de la Constitución Española?\",\n",
    "        \"¿Cuál es el objetivo de la Ley de Enjuiciamiento Criminal?\",\n",
    "        \"¿Qué regula el artículo 20 de la Constitución Española?\",\n",
    "        \"¿Qué es el Tribunal Constitucional en España?\",\n",
    "        \"¿Cuál es el propósito de la Ley de Propiedad Intelectual?\",\n",
    "        \"¿Qué establece el artículo 18 de la Constitución Española?\",\n",
    "        \"¿Qué es la Ley de Transparencia?\",\n",
    "        \"¿Qué regula el artículo 21 de la Constitución Española?\",\n",
    "        \"¿Qué es el derecho de asilo según la ley española?\",\n",
    "        \"¿Qué establece la Ley de Protección de Datos Personales?\",\n",
    "        \"¿Qué es el recurso de amparo según la Constitución Española?\",\n",
    "        \"¿Qué establece el artículo 27 de la Constitución Española?\",\n",
    "        \"¿Qué regula la Ley General de la Seguridad Social?\",\n",
    "        \"¿Qué es el Tribunal Supremo en España?\",\n",
    "        \"¿Qué regula la Ley de Arrendamientos Urbanos?\"\n",
    "    ],\n",
    "    \"context\": [\n",
    "        \"La Ley Orgánica 1/1982 regula el derecho al honor, a la intimidad personal y familiar y a la propia imagen.\",\n",
    "        \"El artículo 14 de la Constitución Española establece que los españoles son iguales ante la ley.\",\n",
    "        \"El artículo 15 de la Constitución Española establece el derecho a la vida y a la integridad física y moral.\",\n",
    "        \"El habeas corpus es un procedimiento que protege la libertad individual contra arrestos y detenciones arbitrarias.\",\n",
    "        \"La Ley Orgánica 3/2007 regula la igualdad efectiva entre mujeres y hombres.\",\n",
    "        \"El artículo 47 de la Constitución Española establece el derecho a disfrutar de una vivienda digna y adecuada.\",\n",
    "        \"La Ley de Enjuiciamiento Criminal regula el proceso penal en España.\",\n",
    "        \"El artículo 20 de la Constitución Española regula la libertad de expresión y de información.\",\n",
    "        \"El Tribunal Constitucional es el intérprete supremo de la Constitución Española.\",\n",
    "        \"La Ley de Propiedad Intelectual protege los derechos de los autores sobre sus obras.\",\n",
    "        \"El artículo 18 de la Constitución Española regula el derecho a la intimidad personal y familiar y a la inviolabilidad del domicilio.\",\n",
    "        \"La Ley de Transparencia promueve la transparencia de la actividad pública y el derecho de acceso a la información.\",\n",
    "        \"El artículo 21 de la Constitución Española regula el derecho de reunión pacífica y sin armas.\",\n",
    "        \"El derecho de asilo protege a las personas que buscan refugio en España por persecución en sus países de origen.\",\n",
    "        \"La Ley de Protección de Datos Personales regula el tratamiento de datos personales y la protección de los derechos de los individuos.\",\n",
    "        \"El recurso de amparo es un mecanismo constitucional que protege los derechos fundamentales.\",\n",
    "        \"El artículo 27 de la Constitución Española establece el derecho a la educación.\",\n",
    "        \"La Ley General de la Seguridad Social regula la protección social en España.\",\n",
    "        \"El Tribunal Supremo es el órgano jurisdiccional superior en todos los órdenes en España.\",\n",
    "        \"La Ley de Arrendamientos Urbanos regula los contratos de alquiler de viviendas y locales.\"\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        {\"answer_start\": 0, \"text\": \"Ley Orgánica 1/1982\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 14\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 15\"},\n",
    "        {\"answer_start\": 0, \"text\": \"habeas corpus\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley Orgánica 3/2007\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 47\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley de Enjuiciamiento Criminal\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 20\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Tribunal Constitucional\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley de Propiedad Intelectual\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 18\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley de Transparencia\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 21\"},\n",
    "        {\"answer_start\": 0, \"text\": \"derecho de asilo\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley de Protección de Datos Personales\"},\n",
    "        {\"answer_start\": 0, \"text\": \"recurso de amparo\"},\n",
    "        {\"answer_start\": 0, \"text\": \"artículo 27\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley General de la Seguridad Social\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Tribunal Supremo\"},\n",
    "        {\"answer_start\": 0, \"text\": \"Ley de Arrendamientos Urbanos\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a Dataset object\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split for model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and evaluation sets\n",
    "train_dataset, eval_dataset = dataset.train_test_split(test_size=0.2).values()\n",
    "\n",
    "# Apply the preprocessing function\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define which model we will use\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/notebooks/TFM_LAW_LLM/fine_tuning_trained_model/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/notebooks/TFM_LAW_LLM/fine_tuning_trained_model/logs\", \n",
    "    logging_steps=100,     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"/notebooks/TFM_LAW_LLM/fine_tuning_trained_model/results\")\n",
    "tokenizer.save_pretrained(\"/notebooks/TFM_LAW_LLM/fine_tuning_trained_model/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and the fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"/notebooks/TFM_LAW_LLM/fine_tuning_trained_model/results\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"¿Cual es la diferencia entre un homicidio y un asesinato?\"\n",
    "context = \"\"\"\n",
    "En el derecho penal español, tanto el homicidio como el asesinato son delitos que implican la muerte de una persona, pero se diferencian en sus características y gravedad. \n",
    "El homicidio, regulado en el artículo 138 del Código Penal, se define como causar la muerte a otra persona sin que concurran circunstancias agravantes. \n",
    "Por otro lado, el asesinato, tipificado en el artículo 139 del Código Penal, es una forma agravada de homicidio que incluye circunstancias específicas como la alevosía, el ensañamiento o la comisión del delito para facilitar otro delito o evitar ser descubierto.\n",
    "Estas diferencias se reflejan en las penas aplicables: el homicidio conlleva una pena de prisión de 10 a 15 años, mientras que el asesinato se castiga con una pena de 15 a 25 años, pudiendo incluso llegar a la prisión permanente revisable en casos extremadamente graves.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=512,\n",
    "    truncation=\"only_second\",\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Get the input IDs and attention mask\n",
    "input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of the Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Get the start and end positions\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "\n",
    "# Convert the scores to probabilities\n",
    "start_prob = torch.softmax(start_scores, dim=1)\n",
    "end_prob = torch.softmax(end_scores, dim=1)\n",
    "\n",
    "# Get the most probable start and end positions\n",
    "start_index = torch.argmax(start_prob)\n",
    "end_index = torch.argmax(end_prob)\n",
    "\n",
    "# Extract the answer from the context\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "answer_tokens = all_tokens[start_index:end_index + 1]\n",
    "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
